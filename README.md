ğŸ§  Logical Fallacy Detection in Climate Change Misinformation

This project builds a multiclass NLP classifier that detects 11 types of logical fallacies found in online climate-change misinformation. It combines:

Classical ML (TF-IDF + Linear SVM)

Transformer-based fine-tuning (DistilRoBERTa)

Dataset balancing via random oversampling

Explainability using Qwen2.5-1.5B-Instruct

The system not only predicts the fallacy but also generates human-readable explanations using a small instruction-tuned LLM.

ğŸ“Œ Features
âœ” Fallacy dataset preprocessing & cleaning
âœ” Baseline classification using LinearSVC
âœ” Transformer finetuning with weighted loss
âœ” Balanced vs. unbalanced comparisons
âœ” Qwen2.5-1.5B-Instruct explainer
âœ” Fully modular codebase (src/)
âœ” Ready for Streamlit deployment

ğŸ—‚ Dataset

The dataset contains the following text components:

fact_checked_segment â€” argument/snippet

comment_by_fact_checker â€” reasoning

article â€” file reference

label_str â€” normalized fallacy label

label_id â€” numeric mapping using labels_climate.py

Fallacy classes include:
CHERRY_PICKING
EVADING_THE_BURDEN_OF_PROOF
FALSE_ANALOGY
FALSE_AUTHORITY
FALSE_CAUSE
HASTY_GENERALISATION
NO_FALLACY
POST_HOC
RED_HERRINGS
STRAWMAN
VAGUENESS

A mapping script (labels_climate.py) ensures consistent ID â†” label conversions.

ğŸ§¹ Preprocessing Pipeline

1ï¸âƒ£ Clean the raw text

Includes:

lowercasing

removing special chars

whitespace normalization

Located in:

src/data/clean_text.py

2ï¸âƒ£ Encode labels

Using:

from src.labels_climate import LABEL2ID, ID2LABEL

3ï¸âƒ£ Drop missing entries

Ensures no NaN text reaches TF-IDF or tokenizers.

Saved in Processed Folder as :
Saved processed datasets to:
data/processed/
   climate_train.csv
   climate_dev.csv
   climate_test.csv
  
4ï¸âƒ£ Dataset balancing

Oversampling minority classes to handle heavy imbalance.

Stored in:

Notebooks/Fallacies_NLP.ipynb

Produces:

data/combined_csv/climate_train_balanced.csv

ğŸ”§ Models Trained
â­ Baseline: TF-IDF + LinearSVM

File:

src/models/baseline.py

This establishes a classical ML benchmark.

ğŸ¤– Transformer: DistilRoBERTa Fine-Tuning

File:

src/models/slm_finetune.py


Includes:

Stratified train/val split

HuggingFace datasets

Weighted loss for class imbalance

Custom WeightedTrainer

Tokenization with truncation & padding

Saving full model + tokenizer

Supports easy loading:

model = AutoModelForSequenceClassification.from_pretrained("outputs/slm_climate_multiclass")

ğŸ’¬ Explainability with Qwen2.5-1.5B-Instruct

File:

src/explainers/explainer_qwen.py


Produces short, human-friendly fallacy explanations.

Example usage:

explainer = QwenExplainer()
explanation = explainer.explain(text, predicted_label)

ğŸ“Š Results Summary
Baseline (Unbalanced)

Accuracy: low due to heavy class imbalance
Model predicts mostly NO_FALLACY

Baseline (Balanced)

Accuracy: improved
Better recall across fallacies
Still limited by TF-IDF representation

Transformer Finetuned (Balanced)

Macro-F1 improved significantly
Performance spread across classes
Still challenging due to dataset complexity

Full tables are in the  notebook & project docs.

ğŸ“ Repository Structure
Steadx01_NLP/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ clean_text.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baseline.py
â”‚   â”‚   â”œâ”€â”€ slm_finetune.py
â”‚   â”‚   â””â”€â”€ __init__.py
|   |
|   |
â”‚   â”‚â”œâ”€â”€ explainer_qwen.py
â”‚   â”‚â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ labels_climate.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ combined_csv/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Fallacies_NLP.ipynb
â”‚   
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ slm_climate_multiclass/   (ignored by .gitignore)
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt

ğŸš€ Installation
1ï¸âƒ£ Clone the repo
git clone https://github.com/SteadyHands01/Steadx01_NLP.git
cd Steadx01_NLP

2ï¸âƒ£ Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ Run Training

Baseline:

python src/models/baseline.py

Transformer:

python src/models/slm_finetune.py

ğŸ’¬ Generate Explanation (Qwen)

Example:

from src.explainers.explainer_qwen import QwenExplainer
explainer = QwenExplainer()
explain = explainer.explain("sample text here", "CHERRY_PICKING")
print(explain)

ğŸ“¦ Future Work

Add Streamlit inference app

Replace DistilRoBERTa with ModernBERT / DeBERTa-v3

Add knowledge distillation

Build a real-time misinformation monitor dashboard

ğŸ™Œ Acknowledgements

HuggingFace Transformers

Qwen team

Scikit-learn

Climate change fallacy dataset authors 
Tariq60: https://github.com/Tariq60/fallacy-detection/tree/master/data

Microsoft (Phi series inspiration)


